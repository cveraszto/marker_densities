{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nrrd\n",
    "from os.path import *\n",
    "import scipy.ndimage\n",
    "from scipy.optimize import curve_fit\n",
    "from pylab import *\n",
    "from JSONread import *\n",
    "from density_function import *\n",
    "import json\n",
    "\n",
    "DATA_FOLDER = \"data/\"\n",
    "OUTPUT_FOLDER = \"output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE = 16\n",
    "MEDIUM_SIZE = 18\n",
    "BIGGER_SIZE = 24\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading annotations\n",
    "annotation, h = nrrd.read(join(DATA_FOLDER, \"annotations.nrrd\"))\n",
    "# old_ann, h = nrrd.read(join(DATA_FOLDER, \"annotation_25_2017.nrrd\"))\n",
    "jsontextfile = open(join(DATA_FOLDER, \"brain_regions.json\"), \"r\")\n",
    "jsoncontent = json.loads(jsontextfile.read())\n",
    "search_children(jsoncontent['msg'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_names = [\"GAD\"]\n",
    "GAD_volume = np.load(join(DATA_FOLDER, \"479_gad1_expr.npy\"))\n",
    "rv = json.loads(open(join(DATA_FOLDER, \"volumes_25.json\"), \"r\").read())\n",
    "literature_file = join(DATA_FOLDER, \"gaba_papers.xlsx\")\n",
    "sheet_indices = [0, 1]\n",
    "num_first_row = 1\n",
    "column_name = 0\n",
    "columns_mean = [[1]]\n",
    "num_marker = len(marker_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques = find_unique_regions(annotation, \n",
    "                        id_to_region_dictionary_ALLNAME, \n",
    "                        region_dictionary_to_id_ALLNAME,\n",
    "                        region_dictionary_to_id_ALLNAME_parent, \n",
    "                        name2allname)\n",
    "\n",
    "children, order_ = find_children(uniques, id_to_region_dictionary_ALLNAME, is_leaf,\n",
    "                                  region_dictionary_to_id_ALLNAME_parent, \n",
    "                                  region_dictionary_to_id_ALLNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lim_GAD=[69,505]\n",
    "GAD_slices = np.array([ 69,  77,  85,  93, 101, 109, 117, 125, 132, 140, 148, 156, 164,\n",
    "       172, 180, 188, 196, 204, 212, 220, 228, 236, 244, 251, 259, 267,\n",
    "       275, 283, 291, 299, 307, 315, 323, 331, 339, 347, 355, 362, 370,\n",
    "       378, 386, 394, 402, 410, 418, 426, 434, 442, 450, 458, 466, 473,\n",
    "       481, 489, 497, 505])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sagital view of the brain to show slices of GAD\n",
    "np.random.seed(182)\n",
    "random_amplitudes = np.random.rand(np.max(uniques))\n",
    "slice_ = int(annotation.shape[2] // 2.5)\n",
    "fig = figure(figsize=(15, 10))\n",
    "imshow(random_amplitudes[annotation[:, :, slice_]].T, interpolation=\"nearest\")\n",
    "for i in GAD_slices:\n",
    "    axvline(x=[i], color='r', linewidth=1)\n",
    "title('GAD slices positions')\n",
    "\n",
    "savefig(join(OUTPUT_FOLDER, 'GAD_slices.png'), dpi=400)\n",
    "close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "names, GADs, down_std_literature, _, convert = read_densities_sheet(\n",
    "                    literature_file, region_keys, columns_mean,\n",
    "                    sheet_indices, num_first_row, column_name)\n",
    "GADs = GADs[0]\n",
    "GADs_std = GADs - down_std_literature[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove regions not in annotation atlas\n",
    "for name in convert.keys():\n",
    "    filter_ = np.where(names==name)\n",
    "    names = np.delete(names, filter_)\n",
    "    GADs = np.delete(GADs, filter_)    \n",
    "    down_std_literature = np.delete(down_std_literature, filter_)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expressions = [[],[],[]]\n",
    "densities = [[],[],[]]\n",
    "dens_stds = [[],[],[]]\n",
    "names_corrected = [[],[],[]]\n",
    "percent_done = 0\n",
    "z_filt = np.ones(annotation.shape[0], dtype=bool)\n",
    "z_filt[GAD_slices] = False\n",
    "\n",
    "for iname, name in enumerate(names):\n",
    "    current_percent = min(int(float(iname) / float(len(names)) * 100.), 100)\n",
    "    if current_percent > percent_done:\n",
    "        progress_bar(current_percent)\n",
    "        percent_done = current_percent\n",
    "    \n",
    "    allname = name2allname[name]\n",
    "    filter_ = filter_region(annotation, allname, children, is_leaf, region_dictionary_to_id_ALLNAME)\n",
    "    \n",
    "    if allname.find(\"Cerebellum\")>=0 or allname.find(\"arbor vitae\")>=0:\n",
    "          # uncomment for CCFv3, filter out Purkinje out\n",
    "#         if \"Purkinje\" in allname:\n",
    "#             continue\n",
    "        place_ = 0\n",
    "      # uncomment for CCFv3, filter out regions not in CCFv2\n",
    "#     elif len(np.where(old_ann==region_dictionary_to_id_ALLNAME[allname])[0])==0:\n",
    "#         continue\n",
    "    elif allname.find(\"Isocortex\")>=0 or allname.find(\"Entorhinal area\")>=0 or allname.find(\"Piriform area\")>=0:\n",
    "          # uncomment for CCFv3, filter out L1 of Cortex\n",
    "#         if \"ayer 1\" in allname:\n",
    "#             continue\n",
    "        place_ = 1\n",
    "    else:\n",
    "        place_ = 2\n",
    "    new_filt = np.copy(filter_)\n",
    "    new_filt[z_filt]=False\n",
    "    if np.any(new_filt):\n",
    "#     z_slices = np.unique(np.where(filter_)[0])\n",
    "#     if not (np.any(filter_[0:lim_GAD[0],:,:]) or np.any(filter_[min(lim_GAD[1], 528):528,:,:]))\\\n",
    "#         and np.any(np.in1d(z_slices, GAD_slices)):\n",
    "#         and (float(GADs[iname])==0 or float(GADs_std[iname])/float(GADs[iname])<=0.05):\n",
    "        expressions[place_].append(np.mean(GAD_volume[new_filt]))\n",
    "        densities[place_].append(float(GADs[iname]))\n",
    "        dens_stds[place_].append(float(GADs_std[iname]))\n",
    "        names_corrected[place_].append(name)\n",
    "    \n",
    "progress_bar(100)\n",
    "densities = np.array(densities)\n",
    "dens_stds = np.array(dens_stds)\n",
    "names_corrected = np.array(names_corrected)\n",
    "expressions = np.array(expressions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_func = lambda x, alpha: alpha*x\n",
    "marker = \"GAD\"\n",
    "alphas = {}\n",
    "stds = {}\n",
    "for ireg, region in enumerate(['Cerebellum', 'Isocortex', 'Rest']):\n",
    "    density = np.array(densities[ireg])\n",
    "    dens_std = np.array(dens_stds[ireg])\n",
    "    expression = np.array(expressions[ireg])\n",
    "    name = np.array(names_corrected[ireg])\n",
    "\n",
    "    filter_ = (~np.isnan(expression))*(density>0)\n",
    "    if np.any(filter_):\n",
    "        figure(figsize=(15,10))\n",
    "        expression = expression[filter_]\n",
    "        density = density[filter_]\n",
    "        name = name[filter_]\n",
    "        dens_std = dens_std[filter_]\n",
    "\n",
    "        max_ = np.max(expression)\n",
    "        for i, percent in zip([3,1,2,0],[1.0, 0.2,0.1, 0.05]):\n",
    "            filter_ = (dens_std/density<percent)\n",
    "            scatter(expression[filter_], density[filter_], c=rcParams['axes.prop_cycle'].by_key()['color'][i])\n",
    "        x = linspace(0, max_, 100, endpoint=False, dtype=float)\n",
    "\n",
    "        solution, pcov = curve_fit(optimize_func, \n",
    "                    xdata=expression, \n",
    "                    ydata=density)\n",
    "        # Display bined standard deviation and name of the points outside it\n",
    "#         low_std = []\n",
    "#         high_std = []\n",
    "#         for i in range(len(x)//2-1):\n",
    "#             filter_ = (expression >= x[i*2])*(expression<x[(i+1)*2])\n",
    "#             if np.any(filter_):\n",
    "#                 error = np.sqrt(np.sum(np.power(density[filter_] - solution[0]*expression[filter_], 2)) / len(density[filter_]))\n",
    "#                 low_std.append(max(x[i*2]*solution[0]-error, 0.))\n",
    "#                 high_std.append(x[i*2]*solution[0]+error)\n",
    "#             else:\n",
    "#                 low_std.append(x[i*2]*solution[0])\n",
    "#                 high_std.append(x[i*2]*solution[0])\n",
    "#             out_std = (density[filter_]<low_std[-1])+(density[filter_]>high_std[-1])\n",
    "#             for i, n in enumerate(name[filter_][out_std]):\n",
    "#                 annotate(n, (expression[filter_][out_std][i], density[filter_][out_std][i]))\n",
    "#         fill_between(x[:-2:2],low_std, high_std, alpha=0.5, color=rcParams['axes.prop_cycle'].by_key()['color'][0])\n",
    "        plot(x, solution[0]*x, 'b', label='y='+str(solution[0])+\"*x\") \n",
    "        plot(x, (solution[0]-2*np.sqrt(pcov[0]))*x, 'g') \n",
    "        plot(x, (solution[0]+2*np.sqrt(pcov[0]))*x, 'g') \n",
    "        alphas[region] = solution[0]\n",
    "        stds[region] = np.sqrt(pcov[0])[0]\n",
    "        xlim([0, max_])\n",
    "        ylabel(\"Region \"+marker+\" density in mm-3 according to Literature\")\n",
    "        xlabel(\"Region mean intensity\")\n",
    "        title(\"Intensity to density ratio for \"+marker+\" from expr image data for \"+region)\n",
    "        legend()\n",
    "        tight_layout()\n",
    "        savefig(join(OUTPUT_FOLDER, 'expr', region+\"_\"+marker+\"_ratio_expr.png\"), dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Alphas: \" + str(alphas))\n",
    "print(\"Standard deviation: \" + str(stds))\n",
    "for name in marker_names:\n",
    "    with open(join(OUTPUT_FOLDER, \"fitting_\" + name + \".json\"), 'w') as fp:\n",
    "        json.dump({\"alphas\": alphas, \"std\": stds}, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
