{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nrrd\n",
    "from os.path import *\n",
    "from pylab import *\n",
    "from JSONread import *\n",
    "from density_function import *\n",
    "import json\n",
    "import xlrd\n",
    "\n",
    "DATA_FOLDER = \"data/\"\n",
    "OUTPUT_FOLDER = \"output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation, h = nrrd.read(join(DATA_FOLDER, \"annotations.nrrd\"))\n",
    "neu_dens, h = nrrd.read(join(DATA_FOLDER, \"neu_density.nrrd\"))\n",
    "num_neurons = json.loads(open(join(DATA_FOLDER, \"neuron_counts.json\"), \"r\").read())\n",
    "jsontextfile = open(join(DATA_FOLDER, \"brain_regions.json\"), \"r\")\n",
    "jsoncontent = json.loads(jsontextfile.read())\n",
    "search_children(jsoncontent['msg'][0])\n",
    "rv = json.loads(open(join(DATA_FOLDER, \"volumes_25.json\"), \"r\").read())\n",
    "voxel_volume = 25**3/1.0e9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques = find_unique_regions(annotation, \n",
    "                        id_to_region_dictionary_ALLNAME, \n",
    "                        region_dictionary_to_id_ALLNAME,\n",
    "                        region_dictionary_to_id_ALLNAME_parent, \n",
    "                        name2allname)\n",
    "\n",
    "children, order_ = find_children(uniques, id_to_region_dictionary_ALLNAME, is_leaf,\n",
    "                                  region_dictionary_to_id_ALLNAME_parent, \n",
    "                                  region_dictionary_to_id_ALLNAME)\n",
    "uniques = uniques[np.argsort(order_)] # order from leaf to biggest regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Choose Markers and their files\n",
    "marker_names = [\"PV\", \"SST\", \"VIP\"] # Careful with the order: should work with the literature file\n",
    "volume_files = [\"868_pvalb_expr.npy\", \"1001_SST_expr.npy\", \"77371835_VIP_expr.npy\"]\n",
    "literature_file = join(DATA_FOLDER, \"densities.xlsx\")\n",
    "sheet_indices = [0]\n",
    "num_first_row = 2\n",
    "column_name = 1\n",
    "columns_mean = [[3, 5], [7, 9], [11, 13]]\n",
    "num_marker = len(marker_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers_intensity = np.zeros((num_marker,) + annotation.shape)\n",
    "for i_marker, filename in enumerate(volume_files):\n",
    "    markers_intensity[i_marker] = np.load(join(DATA_FOLDER, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading results of the fitting pipeline\n",
    "alphas = np.zeros((num_marker, 3))\n",
    "std_fitt = np.zeros((num_marker, 3))\n",
    "for i_marker, name in enumerate(marker_names):\n",
    "    jsoncontent = json.loads(open(join(OUTPUT_FOLDER, \"fitting_\" + name + \".json\"), \"r\").read())\n",
    "    for i_key, key in enumerate([\"Cerebellum\", \"Isocortex\", \"Rest\"]):\n",
    "        if key in jsoncontent[\"alphas\"].keys():\n",
    "            alphas[i_marker][i_key] = jsoncontent[\"alphas\"][key]\n",
    "            std_fitt[i_marker][i_key] = jsoncontent[\"std\"][key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "names, mean_literature, down_std_literature, up_std_literature, convert = read_densities_sheet(\n",
    "                    literature_file, region_keys, columns_mean,\n",
    "                    sheet_indices, num_first_row, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion dictionary from Kim to CCF\n",
    "convert[\"Whole brain\"] = [\"Basic cell groups and regions\"]\n",
    "convert[\"Anterior cingulate area, ventral part, 6\"] = [\"Anterior cingulate area, layer 6a\", \"Anterior cingulate area, layer 6b\"]\n",
    "\n",
    "# Uncomment for CCFv3, corrections for regions which were in CCFv2\n",
    "# for old, new in dict_corrections.items():\n",
    "#     old_name = id_to_region_dictionary[new[0]]+'/3'\n",
    "#     if old_name in convert.keys():\n",
    "#         convert[old_name] = [id_to_region_dictionary[inew] for inew in new]\n",
    "\n",
    "for id_, name in id_to_region_dictionary.items():\n",
    "    if \"layer 6\" in name or \"Layer 6\" in name:\n",
    "        if name[:-1] in convert.keys():\n",
    "            convert[name[:-1]].append(name)\n",
    "\n",
    "invert_convert = {}\n",
    "for k, vs in convert.items():\n",
    "    for v in vs:\n",
    "        invert_convert[v] = k\n",
    "# Regions not found: regions which are merged in CCF mostly\n",
    "print(\"Regions without CCF equivalent:\")\n",
    "for k,v in convert.items():\n",
    "    if len(v)==0:\n",
    "        print(k)\n",
    "        \n",
    "for i_region, name in enumerate(names):\n",
    "    if name in invert_convert.keys():\n",
    "        names[i_region] = invert_convert[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pure non inh regions \n",
    "wb2 = xlrd.open_workbook(join(DATA_FOLDER, \"gaba_papers.xlsx\"))\n",
    "sheet2 = wb2.sheet_by_index(1)\n",
    "ids_pure = []\n",
    "for i_region in range(sheet2.nrows-1): \n",
    "    name = sheet2.cell_value(i_region+1, 0)\n",
    "    if name in region_keys:\n",
    "        value = sheet2.cell_value(i_region+1, 1)\n",
    "        if value<1e-6:\n",
    "            id_reg = region_dictionary_to_id[name]\n",
    "            ids_pure.append(id_reg)\n",
    "uniques = uniques[np.in1d(uniques, ids_pure, invert=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Principal loop, should take a while\n",
    "dens_markers, std_markers = place_cells(annotation, uniques, children, \n",
    "                                        rv, neu_dens, num_neurons,\n",
    "                                        markers_intensity, alphas, std_fitt, \n",
    "                                        names, mean_literature, down_std_literature, up_std_literature,\n",
    "                                        id_to_region_dictionary_ALLNAME, region_dictionary_to_id_ALLNAME,\n",
    "                                        is_leaf, id_to_region_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_marker in range(num_marker):\n",
    "    for id_reg in ids_pure:\n",
    "        std_markers[i_marker][str(id_reg)] = [0., 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dens_markers /= voxel_volume\n",
    "for i_marker, name in enumerate(marker_names):\n",
    "    nrrd.write(join(OUTPUT_FOLDER, \"densities_\" + name + \".nrrd\"), dens_markers[i_marker], header=h)\n",
    "    with open(join(OUTPUT_FOLDER, \"std_\" + name + \".json\"), 'w') as fp:\n",
    "        json.dump(std_markers[i_marker], fp, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dens_PV, h = nrrd.read(join(OUTPUT_FOLDER, \"densities_PV.nrrd\"))\n",
    "dens_SST, h = nrrd.read(join(OUTPUT_FOLDER, \"densities_SST.nrrd\"))\n",
    "dens_VIP, h = nrrd.read(join(OUTPUT_FOLDER, \"densities_VIP.nrrd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "figure(figsize=(20,15))\n",
    "imshow(dens_PV[250,:,:], cmap='hot')\n",
    "colorbar()\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_names = [\"Primary visual area\", \"Primary somatosensory area, lower limb\", \"Prelimbic area\", \"Primary somatosensory area, barrel field\"]\n",
    "colors = [\"darkblue\", \"green\", \"orange\", \"red\"]\n",
    "names = [\"L1\", \"L2\",\"L3\",\"L4\",\"L5\",\"L6a\",\"L6b\"]\n",
    "PVs =[]\n",
    "PVs_std =[]\n",
    "SSTs =[]\n",
    "SSTs_std =[]\n",
    "VIPs =[]\n",
    "VIPs_std =[]\n",
    "figure(figsize=(20,10))\n",
    "for ireg, reg in enumerate(reg_names):\n",
    "    dens_out_PV = np.zeros(7)\n",
    "    dens_std_PV = np.zeros(7)\n",
    "    dens_out_SST = np.zeros(7)\n",
    "    dens_std_SST = np.zeros(7)\n",
    "    dens_out_VIP = np.zeros(7)\n",
    "    dens_std_VIP = np.zeros(7)\n",
    "    ids_roi = children[name2allname[reg]]\n",
    "    for id_child in ids_roi:\n",
    "        pos = -1\n",
    "        filter_ = annotation==id_child\n",
    "        name = id_to_region_dictionary[id_child]\n",
    "        if \"Rostrolateral\" in name:\n",
    "            continue\n",
    "        if \"ayer 1\" in name:\n",
    "            pos = 0\n",
    "        elif \"ayer 2\" in name:\n",
    "            pos = 1\n",
    "        elif \"ayer 3\" in name:\n",
    "            pos = 2\n",
    "        elif \"ayer 4\" in name:\n",
    "            pos = 3\n",
    "        elif \"ayer 5\" in name:\n",
    "            pos = 4\n",
    "        elif \"ayer 6a\" in name:\n",
    "            pos = 5\n",
    "        elif \"ayer 6b\" in name:\n",
    "            pos = 6\n",
    "        dens_out_PV[pos]=np.mean(dens_PV[filter_])\n",
    "        dens_std_PV[pos]=np.std(dens_PV[filter_])\n",
    "        dens_out_SST[pos]=np.mean(dens_SST[filter_])\n",
    "        dens_std_SST[pos]=np.std(dens_SST[filter_])\n",
    "        dens_out_VIP[pos]=np.mean(dens_VIP[filter_])\n",
    "        dens_std_VIP[pos]=np.std(dens_VIP[filter_])\n",
    "    PVs.append(dens_out_PV)\n",
    "    PVs_std.append(dens_std_PV)\n",
    "    SSTs.append(dens_out_SST)\n",
    "    SSTs_std.append(dens_std_SST)\n",
    "    VIPs.append(dens_out_VIP)\n",
    "    VIPs_std.append(dens_std_VIP)    \n",
    "    ax1 = subplot2grid((4,3), (ireg,0), colspan=1, rowspan=1)\n",
    "    ax1.bar(names, dens_out_PV, yerr=dens_std_PV, color=colors[ireg])\n",
    "    ax1.set_title(\"PV layer densities for \"+ reg)\n",
    "    ax1.set_xticks(names)\n",
    "    ax1 = subplot2grid((4,3), (ireg,1), colspan=1, rowspan=1)\n",
    "    ax1.bar(names, dens_out_SST, yerr=dens_std_SST, color=colors[ireg])\n",
    "    ax1.set_title(\"SST layer densities for \"+ reg)\n",
    "    ax1.set_xticks(names)\n",
    "    ax1 = subplot2grid((4,3), (ireg,2), colspan=1, rowspan=1)\n",
    "    ax1.bar(names, dens_out_VIP, yerr=dens_std_VIP, color=colors[ireg])\n",
    "    ax1.set_title(\"VIP layer densities for \"+ reg)\n",
    "    ax1.set_xticks(names)\n",
    "tight_layout()\n",
    "savefig(join(OUTPUT_FOLDER,\"final_densities.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
