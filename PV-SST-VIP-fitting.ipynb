{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nrrd\n",
    "from os.path import *\n",
    "import scipy.ndimage\n",
    "from scipy.optimize import curve_fit\n",
    "from pylab import *\n",
    "import matplotlib.patches as mpatches\n",
    "from JSONread import *\n",
    "from density_function import *\n",
    "import json\n",
    "\n",
    "DATA_FOLDER = \"data/\"\n",
    "OUTPUT_FOLDER = \"output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE = 16\n",
    "MEDIUM_SIZE = 18\n",
    "BIGGER_SIZE = 24\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading annotations\n",
    "annotation, h = nrrd.read(join(DATA_FOLDER, \"annotations.nrrd\"))\n",
    "# Uncomment for ccfv3\n",
    "# old_ann, h = nrrd.read(join(DATA_FOLDER, \"annotation_25_2017.nrrd\"))\n",
    "jsontextfile = open(join(DATA_FOLDER, \"brain_regions.json\"), \"r\")\n",
    "jsoncontent = json.loads(jsontextfile.read())\n",
    "search_children(jsoncontent['msg'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_names = [\"PV\", \"SST\", \"VIP\"]\n",
    "SST_volume = np.load(join(DATA_FOLDER, \"1001_SST_expr.npy\"))\n",
    "VIP_volume = np.load(join(DATA_FOLDER, \"77371835_VIP_expr.npy\"))\n",
    "PV_volume = np.load(join(DATA_FOLDER, \"868_pvalb_expr.npy\"))\n",
    "rv = json.loads(open(join(DATA_FOLDER, \"volumes_25.json\"), \"r\").read())\n",
    "literature_file = join(DATA_FOLDER, \"densities.xlsx\")\n",
    "sheet_indices = [0]\n",
    "num_first_row = 2\n",
    "column_name = 1\n",
    "columns_mean = [[3, 5], [7, 9], [11, 13]]\n",
    "num_marker = len(marker_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques = find_unique_regions(annotation, \n",
    "                        id_to_region_dictionary_ALLNAME, \n",
    "                        region_dictionary_to_id_ALLNAME,\n",
    "                        region_dictionary_to_id_ALLNAME_parent, \n",
    "                        name2allname)\n",
    "\n",
    "children, order_ = find_children(uniques, id_to_region_dictionary_ALLNAME, is_leaf,\n",
    "                                  region_dictionary_to_id_ALLNAME_parent, \n",
    "                                  region_dictionary_to_id_ALLNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lim_VIP=[ 56, 538]\n",
    "VIP_slices = np.array([ 56,  64,  73,  80,  97, 105, 113, 121, 129, 145, 153, 161, 167,\n",
    "       178, 186, 194, 202, 210, 218, 226, 235, 259, 267, 275, 283, 292,\n",
    "       300, 308, 316, 324, 341, 349, 357, 365, 382, 390, 398, 407, 415,\n",
    "       423, 431, 439, 447, 456, 464, 472, 480, 489, 497, 505, 513, 522,\n",
    "       530, 538])[:-2]\n",
    "lim_SST=[64, 391]\n",
    "SST_slices = np.array([ 64,  72,  80,  88,  96, 104, 112, 120, 128, 136, 144, 152, 160,\n",
    "       168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264,\n",
    "       272, 280, 288, 296, 303, 311, 319, 328, 335, 343, 351, 359, 367,\n",
    "       375, 383, 391])\n",
    "lim_PV =[49, 511]\n",
    "PV_slices = np.array([ 49,  57,  74,  82,  91, 100, 109, 117, 126, 134, 144, 152, 160,\n",
    "       169, 177, 186, 195, 203, 211, 220, 228, 236, 245, 254, 262, 270,\n",
    "       279, 287, 295, 304, 312, 321, 329, 338, 346, 354, 362, 371, 379,\n",
    "       387, 395, 403, 411, 419, 428, 436, 445, 453, 461, 470, 478, 486,\n",
    "       494, 502, 511])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sagital view of the brain to show slices of PV, SST and VIP\n",
    "np.random.seed(182)\n",
    "random_amplitudes = np.random.rand(np.max(uniques))\n",
    "slice_ = int(annotation.shape[2] // 2.5)\n",
    "fig = figure(figsize=(15, 30))\n",
    "ax = subplot2grid((30, 1), (0,0), rowspan=10)\n",
    "ax.imshow(random_amplitudes[annotation[:, :, slice_]].T, interpolation=\"nearest\")\n",
    "for i in VIP_slices:\n",
    "    ax.axvline(x=[i], color='r', linewidth=1)\n",
    "ax.set_title('VIP slices positions')\n",
    "\n",
    "ax = subplot2grid((30, 1), (10,0), rowspan=10)\n",
    "ax.imshow(random_amplitudes[annotation[:, :, slice_]].T, interpolation=\"nearest\")\n",
    "for i in SST_slices:\n",
    "    ax.axvline(x=[i], color='r', linewidth=1)\n",
    "ax.set_title('SST slices positions')\n",
    "\n",
    "ax = subplot2grid((30, 1), (20,0), rowspan=10)\n",
    "ax.imshow(random_amplitudes[annotation[:, :, slice_]].T, interpolation=\"nearest\")\n",
    "for i in PV_slices:\n",
    "    ax.axvline(x=[i], color='r', linewidth=1)\n",
    "ax.set_title('PV slices positions')\n",
    "tight_layout()\n",
    "savefig(join(OUTPUT_FOLDER, 'slices.png'), dpi=400)\n",
    "close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "names, marker_means, down_std_literature, _, convert = read_densities_sheet(\n",
    "                    literature_file, region_keys, columns_mean,\n",
    "                    sheet_indices, num_first_row, column_name)\n",
    "\n",
    "PVs = marker_means[0]\n",
    "PVs_std = PVs - down_std_literature[0]\n",
    "SSTs = marker_means[1]\n",
    "SSTs_std = SSTs - down_std_literature[1]\n",
    "VIPs = marker_means[2]\n",
    "VIPs_std = VIPs - down_std_literature[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion dictionary from Kim to CCF\n",
    "convert[\"Whole brain\"] = [\"Basic cell groups and regions\"]\n",
    "convert[\"Anterior cingulate area, ventral part, 6\"] = [\"Anterior cingulate area, layer 6a\", \"Anterior cingulate area, layer 6b\"]\n",
    "\n",
    "# Uncomment for CCFv3, corrections for regions which were in CCFv2\n",
    "# for old, new in dict_corrections.items():\n",
    "#     old_name = id_to_region_dictionary[new[0]]+'/3'\n",
    "#     if old_name in convert.keys():\n",
    "#         convert[old_name] = [id_to_region_dictionary[inew] for inew in new]\n",
    "\n",
    "for id_, name in id_to_region_dictionary.items():\n",
    "    if \"layer 6\" in name or \"Layer 6\" in name:\n",
    "        if name[:-1] in convert.keys():\n",
    "            convert[name[:-1]].append(name)\n",
    "\n",
    "# Regions not found: regions which are merged in CCF mostly\n",
    "print(\"Regions without CCF equivalent:\")\n",
    "for k,v in convert.items():\n",
    "    if len(v)==0:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expressions = [[[],[],[]],[[],[],[]],[[],[],[]]]\n",
    "densities = [[[],[],[]],[[],[],[]],[[],[],[]]]\n",
    "dens_stds = [[[],[],[]],[[],[],[]],[[],[],[]]]\n",
    "names_corrected = [[[],[],[]],[[],[],[]],[[],[],[]]]\n",
    "percent_done = 0\n",
    "SST_filt = np.ones(annotation.shape[0], dtype=bool)\n",
    "SST_filt[SST_slices] = False\n",
    "VIP_filt = np.ones(annotation.shape[0], dtype=bool)\n",
    "VIP_filt[VIP_slices] = False\n",
    "PV_filt = np.ones(annotation.shape[0], dtype=bool)\n",
    "PV_filt[PV_slices] = False\n",
    "\n",
    "for iname, name in enumerate(names):\n",
    "    current_percent = min(int(float(iname) / float(len(names)) * 100.), 100)\n",
    "    if current_percent > percent_done:\n",
    "        progress_bar(current_percent)\n",
    "        percent_done = current_percent\n",
    "\n",
    "    if name in convert.keys():\n",
    "        if len(convert[name])==0:\n",
    "            continue\n",
    "        filter_ = np.zeros(annotation.shape, dtype=bool)\n",
    "#         volume = 0\n",
    "        not_leaf = False\n",
    "        for converted in convert[name]:\n",
    "            allname = name2allname[converted]\n",
    "            if is_leaf[allname]:\n",
    "                filter_ = np.logical_or(filter_, annotation==region_dictionary_to_id[converted])\n",
    "#                 volume += rv[allname]\n",
    "            else: \n",
    "                not_leaf = True\n",
    "                print(name)\n",
    "                break\n",
    "        if not_leaf:\n",
    "            continue\n",
    "    else:\n",
    "        allname = name2allname[name]\n",
    "        filter_ = filter_region(annotation, allname, children, is_leaf, region_dictionary_to_id_ALLNAME)\n",
    "\n",
    "    if allname.find(\"Cerebellum\")>=0 or allname.find(\"arbor vitae\")>=0:\n",
    "        place_ = 0\n",
    "      # Uncomment for CCFv3,filter out regions not in CCFv2\n",
    "#     elif len(np.where(old_ann==region_dictionary_to_id_ALLNAME[allname])[0])==0:\n",
    "#         continue\n",
    "    elif allname.find(\"Isocortex\")>=0 or allname.find(\"Entorhinal area\")>=0 or allname.find(\"Piriform area\")>=0:\n",
    "        # Uncomment for CCFv3, filter out L1 of Cortex\n",
    "#         if \"ayer 1\" in allname:\n",
    "#             continue\n",
    "        place_ = 1\n",
    "    else:\n",
    "        place_ = 2\n",
    "    new_filt = np.copy(filter_)\n",
    "    new_filt[SST_filt]=False\n",
    "    if np.any(new_filt):\n",
    "#     z_slices = np.unique(np.where(filter_)[0])\n",
    "#     if not (np.any(filter_[0:lim_SST[0],:,:]) or np.any(filter_[min(lim_SST[1], 528):528,:,:]))\\\n",
    "#         and np.any(np.in1d(z_slices, SST_slices)):\n",
    "#         and (float(SSTs[iname])==0 or float(SSTs_std[iname])/float(SSTs[iname])<=0.05):\n",
    "        expressions[place_][0].append(np.mean(SST_volume[new_filt]))\n",
    "        densities[place_][0].append(float(SSTs[iname]))\n",
    "        dens_stds[place_][0].append(float(SSTs_std[iname]))\n",
    "        names_corrected[place_][0].append(name)\n",
    "    new_filt = np.copy(filter_)\n",
    "    new_filt[VIP_filt]=False\n",
    "    if np.any(new_filt):\n",
    "#     if not (np.any(filter_[0:lim_VIP[0],:,:]) or np.any(filter_[min(lim_VIP[1], 528):528,:,:]))\\\n",
    "#         and np.any(np.in1d(z_slices, VIP_slices)):\n",
    "#         and (float(VIPs[iname])==0 or float(VIPs_std[iname])/float(VIPs[iname])<=0.05):\n",
    "        expressions[place_][1].append(np.mean(VIP_volume[new_filt]))\n",
    "        densities[place_][1].append(float(VIPs[iname]))\n",
    "        dens_stds[place_][1].append(float(VIPs_std[iname]))\n",
    "        names_corrected[place_][1].append(name)\n",
    "    new_filt = np.copy(filter_)\n",
    "    new_filt[PV_filt]=False\n",
    "    if np.any(new_filt):\n",
    "#     if not (np.any(filter_[0:lim_PV[0],:,:]) or np.any(filter_[min(lim_PV[1], 528):528,:,:]))\\\n",
    "#         and np.any(np.in1d(z_slices, PV_slices)):\n",
    "#         and (float(PVs[iname])==0 or float(PVs_std[iname])/float(PVs[iname])<=0.05):\n",
    "        expressions[place_][2].append(np.mean(PV_volume[new_filt]))\n",
    "        densities[place_][2].append(float(PVs[iname]))\n",
    "        dens_stds[place_][2].append(float(PVs_std[iname]))\n",
    "        names_corrected[place_][2].append(name)\n",
    "    \n",
    "progress_bar(100)\n",
    "densities = np.array(densities)\n",
    "dens_stds = np.array(dens_stds)\n",
    "names_corrected = np.array(names_corrected)\n",
    "expressions = np.array(expressions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimize_func = lambda x, alpha: alpha*x\n",
    "alphas = {\"SST\":{}, \"VIP\":{}, \"PV\":{}}\n",
    "stds = {\"SST\":{}, \"VIP\":{}, \"PV\":{}}\n",
    "for ireg, region in enumerate(['Cerebellum', 'Isocortex', 'Rest']):\n",
    "    for imarker, marker in enumerate([\"SST\", \"VIP\", \"PV\"]):\n",
    "        density = np.array(densities[ireg][imarker])\n",
    "        dens_std = np.array(dens_stds[ireg][imarker])\n",
    "        expression = np.array(expressions[ireg][imarker])\n",
    "        name = np.array(names_corrected[ireg][imarker])\n",
    "\n",
    "        filter_ = (~np.isnan(expression))*(density>0)\n",
    "        if np.any(filter_):\n",
    "            figure(figsize=(15,10))\n",
    "            expression = expression[filter_]\n",
    "            density = density[filter_]\n",
    "            name = name[filter_]\n",
    "            dens_std = dens_std[filter_]\n",
    "\n",
    "            max_ = np.max(expression)\n",
    "            for i, percent in zip([3,1,2,0],[1.0, 0.2,0.1, 0.05]):\n",
    "                filter_ = (dens_std/density<percent)\n",
    "                scatter(expression[filter_], density[filter_], c=rcParams['axes.prop_cycle'].by_key()['color'][i])\n",
    "            x = linspace(0, max_, 100, endpoint=False, dtype=float)\n",
    "\n",
    "            solution, pcov = curve_fit(optimize_func, \n",
    "                        xdata=expression, \n",
    "                        ydata=density)\n",
    "            # Display bined standard deviation and name of the points outside it\n",
    "#             low_std = []\n",
    "#             high_std = []\n",
    "#             for i in range(len(x)//2-1):\n",
    "#                 filter_ = (expression >= x[i*2])*(expression<x[(i+1)*2])\n",
    "#                 if np.any(filter_):\n",
    "#                     error = np.sqrt(np.sum(np.power(density[filter_] - solution[0]*expression[filter_], 2)) / len(density[filter_]))\n",
    "#                     low_std.append(max(x[i*2]*solution[0]-error, 0.))\n",
    "#                     high_std.append(x[i*2]*solution[0]+error)\n",
    "#                 else:\n",
    "#                     low_std.append(x[i*2]*solution[0])\n",
    "#                     high_std.append(x[i*2]*solution[0])\n",
    "#                 out_std = (density[filter_]<low_std[-1])+(density[filter_]>high_std[-1])\n",
    "#                 for i, n in enumerate(name[filter_][out_std]):\n",
    "#                     annotate(n, (expression[filter_][out_std][i], density[filter_][out_std][i]))\n",
    "#             fill_between(x[:-2:2],low_std, high_std, alpha=0.5, color=rcParams['axes.prop_cycle'].by_key()['color'][0])\n",
    "            plot(x, solution[0]*x, 'b', label='y='+str(solution[0])+\"*x\") \n",
    "            plot(x, (solution[0]-2*np.sqrt(pcov[0]))*x, 'g') \n",
    "            plot(x, (solution[0]+2*np.sqrt(pcov[0]))*x, 'g') \n",
    "            alphas[marker][region] = solution[0]\n",
    "            stds[marker][region] = np.sqrt(pcov[0])[0]\n",
    "            xlim([0, max_])\n",
    "            ylabel(\"Region \"+marker+\" density in mm-3 according to Kim et al 2017\")\n",
    "            xlabel(\"Region mean intensity\")\n",
    "            title(\"Intensity to density ratio for \"+marker+\" from expr image data for \"+region)\n",
    "            legend()\n",
    "            tight_layout()\n",
    "            savefig(join(OUTPUT_FOLDER, 'expr', region+\"_\"+marker+\"_ratio_expr.png\"), dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Alphas: \" + str(alphas))\n",
    "print(\"Standard deviation: \" + str(stds))\n",
    "for name in marker_names:\n",
    "    with open(join(OUTPUT_FOLDER, \"fitting_\" + name + \".json\"), 'w') as fp:\n",
    "        json.dump({\"alphas\": alphas[name], \"std\": stds[name]}, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color patches for confidence levels\n",
    "figure(figsize=(5,5))\n",
    "labels = ['< {0}% std/value'.format(i*100.) for i in [1.0, 0.2, 0.1, 0.05]]\n",
    "patches = [mpatches.Patch(color=rcParams['axes.prop_cycle'].by_key()['color'][color], label=label) for label, color in zip(labels, [3,1,2,0])]\n",
    "axis(\"off\")\n",
    "legend(patches, labels, loc='center', title='Confidence')\n",
    "tight_layout()\n",
    "savefig(join(OUTPUT_FOLDER, 'expr', 'confidence.png'), dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional plots\n",
    "## Volume comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wb2 = xlrd.open_workbook(join(DATA_FOLDER, \"volumes.xlsx\")) \n",
    "sheet2 = wb2.sheet_by_index(0)\n",
    "volumes = [0.0] * len(names) \n",
    "volumes_std = [0.0] * len(names)\n",
    "for i_region in range(sheet2.nrows-3): \n",
    "    if \"N/D\" not in [sheet2.cell_value(i_region+2, i) for i in range(3, 6, 2)]:\n",
    "        name = sheet2.cell_value(i_region+2, 1).replace(\"\\xc3\\x88\", \"e\")\n",
    "        if name in names:\n",
    "            i_name = np.where(names==name)[0][0]\n",
    "            volumes[i_name]=(sheet2.cell_value(i_region+2, 3) + sheet2.cell_value(i_region+2, 5))/2\n",
    "            volumes_std[i_name]=(sheet2.cell_value(i_region+2, 4) + sheet2.cell_value(i_region+2, 6))/2\n",
    "volumes = np.array(volumes)\n",
    "            \n",
    "CA_volumes = [0.0]*len(names)\n",
    "for iname, name in enumerate(names):\n",
    "    if name in convert.keys():\n",
    "        for converted in convert[name]:\n",
    "            CA_volumes[iname] += rv[name2allname[converted]]\n",
    "    else:\n",
    "        CA_volumes[iname]=rv[name2allname[name]]\n",
    "CA_volumes = np.array(CA_volumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(15,10))\n",
    "scatter(CA_volumes[volumes>0]/1e9,volumes[volumes>0])\n",
    "ylabel(\"Region volume in mm according to Kim et al 2017\")\n",
    "xlabel(\"Region volume in mm according to Cell Atlas\")\n",
    "title(\"Region volumes comparison.\")\n",
    "legend()\n",
    "tight_layout()\n",
    "savefig(join(OUTPUT_FOLDER, \"region_volumes_comp.png\"), dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard deviation of standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imarker, marker in enumerate([\"SST\", \"VIP\", \"PV\"]):\n",
    "    density = []\n",
    "    dens_std = []\n",
    "    name = []\n",
    "    for ireg, region in enumerate(['Cerebellum', 'Isocortex', 'Rest']):\n",
    "        density = np.concatenate((density, densities[ireg][imarker]))\n",
    "        dens_std = np.concatenate((dens_std, dens_stds[ireg][imarker]))\n",
    "        name = np.concatenate((name, names_corrected[ireg][imarker]))\n",
    "    filter_ = (~np.isnan(density))\n",
    "    if np.any(filter_):\n",
    "        density = density[filter_]\n",
    "        name = name[filter_]\n",
    "        dens_std = dens_std[filter_]\n",
    "        \n",
    "        figure(figsize=(15,10))\n",
    "        x = linspace(0, np.max(density), 100, endpoint=False, dtype=float)\n",
    "        low_std = []\n",
    "        high_std = []\n",
    "        mean_ = []\n",
    "        for i in range(len(x)//2-1):\n",
    "            filter_ = (density >= x[i*2])*(density<x[(i+1)*2])\n",
    "            mean_.append(np.mean(dens_std[filter_]))\n",
    "            std_ = np.std(dens_std[filter_])\n",
    "            if np.any(filter_):\n",
    "                low_std.append(max(mean_[-1]-std_, 0.))\n",
    "                high_std.append(mean_[-1]+std_)\n",
    "            else:\n",
    "                low_std.append(mean_[-1])\n",
    "                high_std.append(mean_[-1])\n",
    "        scatter(density, dens_std)\n",
    "        fill_between(x[:-2:2],low_std, high_std, alpha=0.5, color=rcParams['axes.prop_cycle'].by_key()['color'][0])\n",
    "        plot(x[:-2:2], mean_, 'r')\n",
    "        tight_layout()\n",
    "        savefig(join(OUTPUT_FOLDER, marker+\"_dens_std.png\"), dpi=400)\n",
    "        close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
